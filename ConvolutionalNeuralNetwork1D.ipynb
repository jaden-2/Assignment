{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from keras.datasets import mnist\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1D:\n",
    "    def __init__(self, f_size, initializer, optimizer, p =1, stride=1, n_channel_in = 1, n_channel_out= 1):\n",
    "        self.init = initializer\n",
    "        self.optimizer = optimizer\n",
    "        self.n_channel_in = n_channel_in\n",
    "        self.n_channel_out = n_channel_out\n",
    "        self.stride = stride\n",
    "        self.pad = p\n",
    "        self.n_out = None\n",
    "        self.f_size = f_size\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.n_in = X.shape[-1] # number of features\n",
    "        self.n_samples = X.shape[0] # number of samples\n",
    "\n",
    "        self.x_new = X.reshape(self.n_channel_in, self.n_samples, self.n_in) # reshape into 3D array of (layers, number of samples, number of features)\n",
    "\n",
    "        self.x_new = np.pad(self.x_new, ((0, 0), (0, 0), (self.pad, self.pad))) # Adds padding around row and column for each layer\n",
    "        \n",
    "        self.n_out = num_out(self.n_in, self.pad, self.f_size, self.stride) # calculates the number of output from this convolutional layer\n",
    "        \n",
    "        output = np.zeros((self.n_channel_in, self.n_samples, self.n_out)) # features\n",
    "\n",
    "        # initialization of weights and biases\n",
    "        self.w = self.init.W((self.n_channel_in, 1, self.f_size))\n",
    "        self.b = self.init.B((self.n_channel_in, 1, 1))\n",
    "        \n",
    "        # Loops through each layer, convolutes the rows and columns for each, and performs forward propagation\n",
    "        for i in range(self.n_channel_in):\n",
    "            layer = self.x_new[i]\n",
    "            \n",
    "            for k in range(self.n_samples):\n",
    "                sample = layer[k]\n",
    "                a = np.array([]) # features extracted by filter\n",
    "                for j in range(0, self.x_new.shape[-1], self.stride):\n",
    "                    if j + self.f_size > self.x_new.shape[-1] :\n",
    "                        break\n",
    "                   \n",
    "                    a = np.append(a, np.sum(sample[j: j + self.f_size] @ self.w[i][0] + self.b[i][0]))\n",
    "                    \n",
    "\n",
    "     \n",
    "                output[i, k] = a\n",
    "            #a = np.array(a).reshape(1, 1, a.shape[-1]) # reshape into (1, 1, number of features)\n",
    "            #output = np.append(output, a, axis=0) # appended extracted features to layer\n",
    "        #print(output.sum(axis=0))\n",
    "        return output.sum(axis=0)\n",
    "\n",
    "   ## Work on backward propagation, verfiy using note to get the shapes of dx, dw, db \n",
    "    def backward(self, dA):\n",
    "\n",
    "        dA = dA.reshape(self.n_channel_in, self.n_samples, self.n_in)\n",
    "        self.dB = np.sum(dA, axis=( 1, -1), dtype=np.float64)\n",
    "\n",
    "        n_in = self.x_new.shape[-1] # number of input features\n",
    "        self.dW = np.zeros((self.n_channel_in, self.n_samples, self.f_size))\n",
    "       \n",
    "\n",
    "        \n",
    "        l = dA.shape[-1]\n",
    "        \n",
    "        for i in range(self.n_channel_in): # Loops for each channel\n",
    "            layer = self.x_new[i]\n",
    "  \n",
    "            for k in range(self.n_samples): # loops for each sample\n",
    "                w = np.array([])\n",
    "                sample = layer\n",
    "                for j in range(0, n_in, self.stride): # loops through the columns of each sample\n",
    "                    if j + l > n_in:\n",
    "                        break          \n",
    "                    \n",
    "                    w = np.append(w, dA[i, k] @ sample[k, j: j + l])    \n",
    "                \n",
    "                self.dW[i] = w\n",
    "        self.dW = np.sum(self.dW, axis=1)\n",
    "        #self.dW = self.dW[np.newaxis, :]\n",
    "\n",
    "        self.dx = np.zeros((self.n_channel_in, 1, self.f_size))\n",
    "\n",
    "        a = np.pad(dA, ((0, 0), (0, 0), (self.pad, self.pad)))\n",
    "        dx = np.ones((self.n_channel_in, dA.shape[1], self.n_out))\n",
    "\n",
    "        for  i in range(self.n_channel_in):\n",
    "            layer = a[i]\n",
    "            weight = self.w[i]\n",
    "            w = np.array([])\n",
    "            for j in range(0, a.shape[-1], self.stride):\n",
    "                if j + self.f_size > a.shape[-1]:\n",
    "                    break\n",
    "                w = np.append(w, layer[:, j: j+self.f_size][0] @ weight[0])\n",
    "            dx[i] = w\n",
    "        self.optimizer.update(self)\n",
    "        return dx\n",
    "            \n",
    "\n",
    "def num_out(n_in, pad, f, s):\n",
    "    \"\"\"\n",
    "    ##### self.n_in: number of features\n",
    "    ##### pad: Number of padding on one side\n",
    "    ##### s: stride value\n",
    "\n",
    "    ##### Returns: Number of output of convolution\n",
    "    \"\"\"\n",
    "    n_out = ((n_in + 2*pad - f)/ s) +1\n",
    "    return int(n_out)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    Number of nodes Fully connected layer from n_nodes1 to n_nodes2\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      Number of nodes in the previous layer\n",
    "    n_nodes2 : int\n",
    "      Number of nodes in the later layer\n",
    "    initializer: instance of initialization method\n",
    "    optimizer: instance of optimization method\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self.w = initializer.W((n_nodes1, n_nodes2))\n",
    "        self.b = initializer.B((n_nodes2,))\n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        forward\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : The following forms of ndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : The following forms of ndarray, shape (batch_size, n_nodes2)\n",
    "            output\n",
    "        \"\"\"        \n",
    "        self.Z = X\n",
    "        A = X @ self.w + self.b\n",
    "        \n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        Backward\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : The following forms of ndarray, shape (batch_size, n_nodes2)\n",
    "            Gradient flowing from behind\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : The following forms of ndarray, shape (batch_size, n_nodes1)\n",
    "            Gradient to flow forward\n",
    "        \"\"\"\n",
    "        \n",
    "        # update\n",
    "        self.dB = np.sum(dA, axis=0)\n",
    "\n",
    "       # print(self.dB)\n",
    "        self.dW = self.Z.T @ dA \n",
    "        self.dZ = dA @ self.w.T\n",
    "        \n",
    "        self.optimizer.update(self)\n",
    "        \n",
    "        return self.dZ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    Simple initialization with Gaussian distribution\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      Standard deviation of Gaussian distribution\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, shape):\n",
    "        \"\"\"\n",
    "        Weight initialization\n",
    "        Parameters\n",
    "        ----------\n",
    "        Shape: tuple\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        w = self.sigma * np.random.randn(*shape)\n",
    "        \n",
    "        return w\n",
    "    \n",
    "    def B(self, shape):\n",
    "        \"\"\"\n",
    "        Bias initialization\n",
    "        Parameters\n",
    "        ----------\n",
    "        shape : tuple\n",
    "          Number of nodes in the later layer\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(*shape)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.A = X\n",
    "        return np.clip(X, 0, None)\n",
    "    \n",
    "    def backward(self, X):\n",
    "        a = X > 0\n",
    "        return X * np.clip(np.sign(self.A), 0, None)\n",
    "\n",
    "class Tanh:\n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        return np.tanh(A)\n",
    "    def backward(self, dZ):\n",
    "        return dZ * (1 - (np.tanh(self.A))**2)\n",
    "\n",
    "class Softmax():\n",
    "        def __init__(self) -> None:\n",
    "            pass\n",
    "\n",
    "\n",
    "        def forward(self, a):\n",
    "            numerator = np.exp(a)\n",
    "            self.dZ = numerator / np.sum(np.exp(a), axis=1).reshape(-1, 1)\n",
    "            return self.dZ\n",
    "        \n",
    "        def backward(self, Y):\n",
    "             self.loss = self.loss_func(Y)   \n",
    "                      \n",
    "             return self.dZ - Y\n",
    "        \n",
    "        def loss_func(self, Y, Z = None):             \n",
    "            if type(Z) == type(None):\n",
    "                Z = self.dZ\n",
    "\n",
    "            loss = -1* np.sum(Y * np.log(Z + 1e-7))\n",
    "\n",
    "            return loss/len(Y)\n",
    "\n",
    "            \n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr \n",
    "        self.HW = 1\n",
    "        self.HB = 1\n",
    "\n",
    "    def update(self, layer):\n",
    "\n",
    "        self.HW += layer.dW**2\n",
    "        self.HB += layer.dB**2\n",
    "\n",
    "        layer.w -= self.lr * np.sqrt(1/self.HW) * (layer.dW)\n",
    "        layer.b -= self.lr * np.sqrt(1/self.HB) *  layer.dB\n",
    "\n",
    "\n",
    "class SGD:\n",
    "    \"\"\"\n",
    "    Stochastic gradient descent\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : Learning rate\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        The weight or bias of a certain layer\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : Instance of the layer before update\n",
    "        \"\"\"\n",
    "\n",
    "        layer.w -= self.lr * layer.dW\n",
    "        layer.b -= self.lr * layer.dB\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "Iterator to get a mini-batch\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : The following forms of ndarray, shape (n_samples, n_features)\n",
    "      Training data\n",
    "    y : The following form of ndarray, shape (n_samples, 1)\n",
    "      Correct answer value\n",
    "    batch_size : int\n",
    "      Batch size\n",
    "    seed : int\n",
    "      NumPy random seed\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int_)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SratchConvolutionalNeuralNetwork1D:\n",
    "    def __init__(self, epoch=10, lr=0.01, batch_size=20, padding =1, n_features=784, n_nodes1=400, n_nodes2=200, n_output=10, filter_size = 3, verbose=True, initilizer = SimpleInitializer, Optimizer= AdaGrad, Activater = Tanh):\n",
    "        self.epoch = epoch\n",
    "        self.p = padding\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.n_features = n_features\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.n_output = n_output\n",
    "        self.f_size = filter_size\n",
    "        self.verbose = verbose\n",
    "        self.optimizer = Optimizer\n",
    "        self.init = initilizer(0.05)\n",
    "        self.activater = Activater\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "    def fit(self, X, y, x_val = None, y_val= None):\n",
    "\n",
    "        # neural network layers\n",
    "        self.CN1 = Conv1D(self.f_size,self.init, self.optimizer(self.lr), p=self.p) \n",
    "        self.CN1.n_out = num_out(X.shape[-1], self.CN1.f_size, self.CN1.pad, self.CN1.stride)\n",
    "        \n",
    "        self.activater1 = self.activater()\n",
    "        # fully connected layers\n",
    "        self.FC2 = FC(self.n_features, self.n_nodes2, self.init, self.optimizer(self.lr))\n",
    "        self.activater2 = self.activater()\n",
    "\n",
    "        self.FC3 = FC(self.n_nodes2, self.n_output, self.init, self.optimizer(self.lr))\n",
    "\n",
    "        # output layer\n",
    "        self.FC3 = FC(self.n_nodes2, self.n_output, self.init, self.optimizer(self.lr))\n",
    "        self.activater3 = Softmax()\n",
    "\n",
    "\n",
    "        self.loss = []\n",
    "        self.loss_epoch = [self.activater3.loss_func(y, self._forward(X))]\n",
    "\n",
    "        for _ in range(self.epoch):\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size)\n",
    "\n",
    "            for mini_x_train, mini_y_train in get_mini_batch:\n",
    "                # forward propagation\n",
    "                self._forward(mini_x_train)\n",
    "                #backward \n",
    "                self._backward(mini_y_train)\n",
    "                self.loss.append(self.activater3.loss)\n",
    "\n",
    "            self.loss_epoch.append(self.activater3.loss_func(y, self._forward(X)))\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f\"({_}) : {self.loss_epoch}\")\n",
    "                \n",
    "            \n",
    "                        \n",
    "        return self\n",
    "\n",
    "    def _forward(self, X):\n",
    "        # first hidden layer\n",
    "\n",
    "        A1 = self.CN1.forward(X)    \n",
    "        A1 = A1.reshape(-1, self.n_features)\n",
    "\n",
    "        Z1 = self.activater1.forward(A1)\n",
    "        A2 = self.FC2.forward(Z1)\n",
    "        Z2 = self.activater2.forward(A2)\n",
    "        A3 = self.FC3.forward(Z2)\n",
    "        Z3 = self.activater3.forward(A3)\n",
    "\n",
    "        return Z3\n",
    "\n",
    "    def _backward(self, y):\n",
    "        # Output layer\n",
    "        dA3 = self.activater3.backward(y) \n",
    "        dZ2 = self.FC3.backward(dA3)\n",
    "        dA2 = self.activater2.backward(dZ2)\n",
    "        dZ1 = self.FC2.backward(dA2)\n",
    "        dA1 = self.activater1.backward(dZ1)\n",
    "\n",
    "        dA1 = dA1.flatten()   \n",
    "        dZ0 = self.CN1.backward(dA1) \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "\n",
    "x_test = x_test.reshape(-1, 784)\n",
    "\n",
    "x_train, x_test = x_train.astype(np.float_), x_test.astype(np.float_)\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print(x_train.max())\n",
    "print(x_test.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 1)"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].reshape(-1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "onv = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "\n",
    "one_hot_y_train = onv.fit_transform(y_train[:, np.newaxis])\n",
    "one_hot_y_test = onv.fit_transform(y_test[:, np.newaxis])\n",
    "\n",
    "print(one_hot_y_test.shape)\n",
    "print(one_hot_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(12000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, one_hot_y_train, test_size=0.2)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 784)\n",
      "(300, 10)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train[:300]\n",
    "y_train = y_train[:300]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0) : [2.2933374181752173, 2.313932879914867]\n",
      "(1) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223]\n",
      "(2) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813]\n",
      "(3) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415]\n",
      "(4) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235]\n",
      "(5) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057]\n",
      "(6) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235]\n",
      "(7) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293]\n",
      "(8) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484]\n",
      "(9) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336]\n",
      "(10) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516]\n",
      "(11) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552]\n",
      "(12) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928]\n",
      "(13) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283]\n",
      "(14) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698]\n",
      "(15) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895]\n",
      "(16) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787]\n",
      "(17) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973]\n",
      "(18) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003]\n",
      "(19) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778]\n",
      "(20) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685]\n",
      "(21) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515]\n",
      "(22) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064]\n",
      "(23) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064, 2.316470589264725]\n",
      "(24) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064, 2.316470589264725, 2.3166445037838175]\n",
      "(25) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064, 2.316470589264725, 2.3166445037838175, 2.3168195989305773]\n",
      "(26) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064, 2.316470589264725, 2.3166445037838175, 2.3168195989305773, 2.3169957908493717]\n",
      "(27) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064, 2.316470589264725, 2.3166445037838175, 2.3168195989305773, 2.3169957908493717, 2.3171730097069014]\n",
      "(28) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064, 2.316470589264725, 2.3166445037838175, 2.3168195989305773, 2.3169957908493717, 2.3171730097069014, 2.317351197614512]\n",
      "(29) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064, 2.316470589264725, 2.3166445037838175, 2.3168195989305773, 2.3169957908493717, 2.3171730097069014, 2.317351197614512, 2.3175303068649047]\n",
      "(30) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064, 2.316470589264725, 2.3166445037838175, 2.3168195989305773, 2.3169957908493717, 2.3171730097069014, 2.317351197614512, 2.3175303068649047, 2.3177102984304816]\n",
      "(31) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064, 2.316470589264725, 2.3166445037838175, 2.3168195989305773, 2.3169957908493717, 2.3171730097069014, 2.317351197614512, 2.3175303068649047, 2.3177102984304816, 2.317891140680728]\n",
      "(32) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064, 2.316470589264725, 2.3166445037838175, 2.3168195989305773, 2.3169957908493717, 2.3171730097069014, 2.317351197614512, 2.3175303068649047, 2.3177102984304816, 2.317891140680728, 2.3180728082839828]\n",
      "(33) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064, 2.316470589264725, 2.3166445037838175, 2.3168195989305773, 2.3169957908493717, 2.3171730097069014, 2.317351197614512, 2.3175303068649047, 2.3177102984304816, 2.317891140680728, 2.3180728082839828, 2.3182552812651633]\n",
      "(34) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064, 2.316470589264725, 2.3166445037838175, 2.3168195989305773, 2.3169957908493717, 2.3171730097069014, 2.317351197614512, 2.3175303068649047, 2.3177102984304816, 2.317891140680728, 2.3180728082839828, 2.3182552812651633, 2.318438544195984]\n",
      "(35) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064, 2.316470589264725, 2.3166445037838175, 2.3168195989305773, 2.3169957908493717, 2.3171730097069014, 2.317351197614512, 2.3175303068649047, 2.3177102984304816, 2.317891140680728, 2.3180728082839828, 2.3182552812651633, 2.318438544195984, 2.318622585498159]\n",
      "(36) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064, 2.316470589264725, 2.3166445037838175, 2.3168195989305773, 2.3169957908493717, 2.3171730097069014, 2.317351197614512, 2.3175303068649047, 2.3177102984304816, 2.317891140680728, 2.3180728082839828, 2.3182552812651633, 2.318438544195984, 2.318622585498159, 2.318807396843287]\n",
      "(37) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064, 2.316470589264725, 2.3166445037838175, 2.3168195989305773, 2.3169957908493717, 2.3171730097069014, 2.317351197614512, 2.3175303068649047, 2.3177102984304816, 2.317891140680728, 2.3180728082839828, 2.3182552812651633, 2.318438544195984, 2.318622585498159, 2.318807396843287, 2.3189929726357006]\n",
      "(38) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064, 2.316470589264725, 2.3166445037838175, 2.3168195989305773, 2.3169957908493717, 2.3171730097069014, 2.317351197614512, 2.3175303068649047, 2.3177102984304816, 2.317891140680728, 2.3180728082839828, 2.3182552812651633, 2.318438544195984, 2.318622585498159, 2.318807396843287, 2.3189929726357006, 2.3191793095667075]\n",
      "(39) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064, 2.316470589264725, 2.3166445037838175, 2.3168195989305773, 2.3169957908493717, 2.3171730097069014, 2.317351197614512, 2.3175303068649047, 2.3177102984304816, 2.317891140680728, 2.3180728082839828, 2.3182552812651633, 2.318438544195984, 2.318622585498159, 2.318807396843287, 2.3189929726357006, 2.3191793095667075, 2.3193664062303956]\n",
      "(40) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064, 2.316470589264725, 2.3166445037838175, 2.3168195989305773, 2.3169957908493717, 2.3171730097069014, 2.317351197614512, 2.3175303068649047, 2.3177102984304816, 2.317891140680728, 2.3180728082839828, 2.3182552812651633, 2.318438544195984, 2.318622585498159, 2.318807396843287, 2.3189929726357006, 2.3191793095667075, 2.3193664062303956, 2.319554262792618]\n",
      "(41) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064, 2.316470589264725, 2.3166445037838175, 2.3168195989305773, 2.3169957908493717, 2.3171730097069014, 2.317351197614512, 2.3175303068649047, 2.3177102984304816, 2.317891140680728, 2.3180728082839828, 2.3182552812651633, 2.318438544195984, 2.318622585498159, 2.318807396843287, 2.3189929726357006, 2.3191793095667075, 2.3193664062303956, 2.319554262792618, 2.3197428807060145]\n",
      "(42) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064, 2.316470589264725, 2.3166445037838175, 2.3168195989305773, 2.3169957908493717, 2.3171730097069014, 2.317351197614512, 2.3175303068649047, 2.3177102984304816, 2.317891140680728, 2.3180728082839828, 2.3182552812651633, 2.318438544195984, 2.318622585498159, 2.318807396843287, 2.3189929726357006, 2.3191793095667075, 2.3193664062303956, 2.319554262792618, 2.3197428807060145, 2.319932262464903]\n",
      "(43) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064, 2.316470589264725, 2.3166445037838175, 2.3168195989305773, 2.3169957908493717, 2.3171730097069014, 2.317351197614512, 2.3175303068649047, 2.3177102984304816, 2.317891140680728, 2.3180728082839828, 2.3182552812651633, 2.318438544195984, 2.318622585498159, 2.318807396843287, 2.3189929726357006, 2.3191793095667075, 2.3193664062303956, 2.319554262792618, 2.3197428807060145, 2.319932262464903, 2.3201224113947725]\n",
      "(44) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064, 2.316470589264725, 2.3166445037838175, 2.3168195989305773, 2.3169957908493717, 2.3171730097069014, 2.317351197614512, 2.3175303068649047, 2.3177102984304816, 2.317891140680728, 2.3180728082839828, 2.3182552812651633, 2.318438544195984, 2.318622585498159, 2.318807396843287, 2.3189929726357006, 2.3191793095667075, 2.3193664062303956, 2.319554262792618, 2.3197428807060145, 2.319932262464903, 2.3201224113947725, 2.3203133314718034]\n",
      "(45) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064, 2.316470589264725, 2.3166445037838175, 2.3168195989305773, 2.3169957908493717, 2.3171730097069014, 2.317351197614512, 2.3175303068649047, 2.3177102984304816, 2.317891140680728, 2.3180728082839828, 2.3182552812651633, 2.318438544195984, 2.318622585498159, 2.318807396843287, 2.3189929726357006, 2.3191793095667075, 2.3193664062303956, 2.319554262792618, 2.3197428807060145, 2.319932262464903, 2.3201224113947725, 2.3203133314718034, 2.320505027168468]\n",
      "(46) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064, 2.316470589264725, 2.3166445037838175, 2.3168195989305773, 2.3169957908493717, 2.3171730097069014, 2.317351197614512, 2.3175303068649047, 2.3177102984304816, 2.317891140680728, 2.3180728082839828, 2.3182552812651633, 2.318438544195984, 2.318622585498159, 2.318807396843287, 2.3189929726357006, 2.3191793095667075, 2.3193664062303956, 2.319554262792618, 2.3197428807060145, 2.319932262464903, 2.3201224113947725, 2.3203133314718034, 2.320505027168468, 2.320697503321801]\n",
      "(47) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064, 2.316470589264725, 2.3166445037838175, 2.3168195989305773, 2.3169957908493717, 2.3171730097069014, 2.317351197614512, 2.3175303068649047, 2.3177102984304816, 2.317891140680728, 2.3180728082839828, 2.3182552812651633, 2.318438544195984, 2.318622585498159, 2.318807396843287, 2.3189929726357006, 2.3191793095667075, 2.3193664062303956, 2.319554262792618, 2.3197428807060145, 2.319932262464903, 2.3201224113947725, 2.3203133314718034, 2.320505027168468, 2.320697503321801, 2.3208907650213546]\n",
      "(48) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064, 2.316470589264725, 2.3166445037838175, 2.3168195989305773, 2.3169957908493717, 2.3171730097069014, 2.317351197614512, 2.3175303068649047, 2.3177102984304816, 2.317891140680728, 2.3180728082839828, 2.3182552812651633, 2.318438544195984, 2.318622585498159, 2.318807396843287, 2.3189929726357006, 2.3191793095667075, 2.3193664062303956, 2.319554262792618, 2.3197428807060145, 2.319932262464903, 2.3201224113947725, 2.3203133314718034, 2.320505027168468, 2.320697503321801, 2.3208907650213546, 2.3210848175142784]\n",
      "(49) : [2.2933374181752173, 2.313932879914867, 2.3138031103858223, 2.313755667231813, 2.3137588632019415, 2.3137969699404235, 2.3138607161631057, 2.313944071619235, 2.314042853824293, 2.3141540276576484, 2.3142753158194336, 2.3144049655594516, 2.314541600825552, 2.31468412421928, 2.3148316495322283, 2.314983453870698, 2.315138942780895, 2.3152976242675787, 2.315459089057973, 2.3156229953530003, 2.315789056868778, 2.315957033334685, 2.3161267228555515, 2.3162979557093064, 2.316470589264725, 2.3166445037838175, 2.3168195989305773, 2.3169957908493717, 2.3171730097069014, 2.317351197614512, 2.3175303068649047, 2.3177102984304816, 2.317891140680728, 2.3180728082839828, 2.3182552812651633, 2.318438544195984, 2.318622585498159, 2.318807396843287, 2.3189929726357006, 2.3191793095667075, 2.3193664062303956, 2.319554262792618, 2.3197428807060145, 2.319932262464903, 2.3201224113947725, 2.3203133314718034, 2.320505027168468, 2.320697503321801, 2.3208907650213546, 2.3210848175142784, 2.3212796661252546]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.SratchConvolutionalNeuralNetwork1D at 0x1b3918237a0>"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SratchConvolutionalNeuralNetwork1D(epoch=50, batch_size=20, padding=1, filter_size=3, lr=0.001, verbose=True, Activater=Tanh)\n",
    "model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Learning Loss of CNN 1d model\")\n",
    "plt.plot(model.loss_epoch)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
